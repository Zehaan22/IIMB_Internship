evals <- sapply(mu.k, log.like, X)
plot(mu.x, ll.est, type = 'l', ylab = "log-likelihood", xlab = expression(mu))
points(mu.k, evals, pch = 16, col = rgb(0,0,1, alpha = .5))
## Loop below stops when |mu_(k+1) - mu_(k)| < tol
current <- 7  # Bad starting value
diff <- 100
iter <- 0
mu.k <- current
while( (diff > tol) && iter < 100)
{
iter <- iter + 1
update <- current - f.prime(X, current)/f.double.prime(X, current)
mu.k <- c(mu.k, update)
diff <- abs(current - update)
current <- update
}
current  # final approximation to MLE
evals <- sapply(mu.k, log.like, X)
points(mu.k, evals, pch = 16, col = rgb(1,0,0, alpha = .5))
current <- 19  # Worst starting value
diff <- 100
iter <- 0
mu.k <- current
while( (diff > tol) && iter < 100)
{
iter <- iter + 1
update <- current - f.prime(X, current)/f.double.prime(X, current)
mu.k <- c(mu.k, update)
diff <- abs(current - update)
current <- update
}
current  # final approximation to MLE
evals <- sapply(mu.k, log.like, X)
points(mu.k, evals, pch = 16, col = rgb(.2,.7,.1, alpha = .8))
legend("topright", legend = c("Good starting", "Bad starting", "Horrible starting"), pch = 16, col = c("blue", "red", rgb(.2,.7,.1)))
titanic <- read.csv("https://dvats.github.io/assets/titanic.csv")
head(titanic)
titanic <- read.csv("https://dvats.github.io/assets/titanic.csv")
head(titanic)
Y <- titanic$Survived
f.gradient <- function(y, X, beta)
{
# converting beta to compatible matrix form
beta <- matrix(beta, ncol = 1)
pi.vec <- 1 / (1 + exp(-X%*%beta))
rtn <- colSums(X* as.numeric(y - pi.vec))
return(rtn)
}
f.hessian <- function(y, X, beta)
{
beta <- matrix(beta, ncol = 1)
W_i <- exp(X%*%beta) / (1 + exp(X%*%beta))^2
W <- diag(as.numeric(W_i))
rtn <- - t(X) %*% W %*% X
}
tol <- 1e-10
compare <- 100
iter <- 1
# starting from the zero-vector
grad.vec <- c() # will store gradients here
beta.current <- rep(0, p)
p <- dim(X)[2]
y <- titanic$Survived
X <- as.matrix(titanic[, -1]) # everything but the first column is the X
# will need these later
p <- dim(X)[2]
n <- length(y)
tol <- 1e-10
compare <- 100
iter <- 1
# starting from the zero-vector
grad.vec <- c() # will store gradients here
beta.current <- rep(0, p)
beta.new <- beta.current
while(compare > tol)
{
iter <- iter + 1 # tracking iterations
gradient <- f.gradient(y, X, beta.current)
hessian <- f.hessian(y, X, beta.current)
beta.new <- beta.current - qr.solve(hessian) %*% gradient
grad.vec[iter] <- norm(gradient, "2")
beta.current <- beta.new
compare <- grad.vec[iter]
}
iter
beta.new
# 1 for intercept, 1 for male,
jack.x <- c(1, 1, 20, 0, 0, 7.5)
rose.x <- c(1, 0, 19, 1, 1, 512)
# estimate from logistic reg is in beta.new
pi.jack <- 1/ (1 + exp( - sum(jack.x * beta.new)))
pi.rose <- 1/ (1 + exp( - sum(rose.x * beta.new)))
library(rvest)
html <- read_html("https://en.wikipedia.org/wiki/List_of_countries_by_age_structure")
dat.table <- html%>%html_table()
dat.table[[1]]
country.table <- dat.table[[1]]
write.csv(country.table, "Age_Proportions.csv")
View(html)
continents <- unique(data.suicides$continent)
data.suicides <- read.csv("suicide_cleaned.csv")
head(data.suicides)
data.urban.bliss <- read.csv("- train US new.csv")
head(data.urban.bliss)
data.happiness <- read.csv("Happiness_cleaned.csv")
head(data.happiness)
continents <- unique(data.suicides$continent)
for(cont in continents){
dat <- data.suicides[which(data.suicides$continent == cont),]
gdps <- unique(dat$gdp_per_capita)
gdps <- sort(gdps)
suicides <- numeric(length = length(gdps))
counter <- 1
for(i in gdps){
suicides[counter] <- sum(dat$suicides.100k.pop[which(dat$gdp_per_capita == i)])
counter <- counter + 1
}
plot(gdps,suicides,'l', xlab = "GDP per capita", ylab = "No. of Suicides", main = paste("GDP vs. Suicide Rate for", cont))
}
dat.happy <- data.happiness[which(data.happiness$Continent == "Europe"),]
plot(dat.happy$Economy..GDP.per.Capita., dat.happy$Happiness.Score,
xlab = "GDP per Capita",
ylab = "Happiness Score",
main = "Europe")
abline(lm(dat.happy$Happiness.Score~dat.happy$Economy..GDP.per.Capita.),col = "red")
legend("bottomright", "Line of Best Fit", fill = "red")
continents <- unique(data.suicides$continent)
for(cont in continents){
dat.happy <- data.happiness[which(data.happiness$Continent == cont),]
plot(dat.happy$Economy..GDP.per.Capita., dat.happy$Happiness.Score,
xlab = "GDP per Capita",
ylab = "Happiness Score",
main = cont)
abline(lm(dat.happy$Happiness.Score~dat.happy$Economy..GDP.per.Capita.),col = "red")
legend("bottomright", "Line of Best Fit", fill = "red")
}
dat.happy <- data.happiness[which(data.happiness$Continent == "Europe"),]
plot(dat.happy$Economy..GDP.per.Capita., dat.happy$Health..Life.Expectancy.,
xlab = "GDP per Capita",
ylab = "Health Index",
main = "Europe")
abline(lm(dat.happy$Health..Life.Expectancy.~dat.happy$Economy..GDP.per.Capita.),col = "red")
legend("bottomright", "Line of Best Fit", fill = "red")
cor(dat.happy$Health..Life.Expectancy.,fitted(lm(dat.happy$Health..Life.Expectancy.~dat.happy$Economy..GDP.per.Capita.))) # multiple correlation
Continents <- unique(data.suicides$continent)
corr.values <- data.frame(Continents)
values <- numeric(length = length(Continents))
counter = 1
for(cont in continents){
dat.happy <- data.happiness[which(data.happiness$Continent == cont),]
values[counter] <- (cor(dat.happy$Health..Life.Expectancy.,fitted(lm(dat.happy$Health..Life.Expectancy.~dat.happy$Economy..GDP.per.Capita.)))
)
counter <- counter + 1
}
corr.values$`Corr Values`<-values
corr.values
boxplot(Happiness.Score ~ Continent, data = data.happiness, col = 'coral')
upper <- c("Europe", "North America", "Asia", "Europe; Asia")
top.happiness <- data.happiness[data.happiness$Continent %in% upper,]
bot.happiness <- data.happiness[!data.happiness$Continent %in% upper,]
top.score <- top.happiness$Happiness.Score
bot.score <- bot.happiness$Happiness.Score
m.top <- mean(top.score)
m.bot <- mean(bot.score)
n1 <- length(top.score)
n2 <- length(bot.score)
m <- m.top - m.bot
s <- sqrt(1/n1 + 1/n2) * sqrt((sum((top.score - m.top)^2) + sum((bot.score - m.bot)^2))/(n1 + n2 - 2))
paste0("Difference is Mean of happiness index in Upper Hemisphere to Lower Hemisphere : ", m)
paste0("Deviation in the mean differene : ", s)
paste0("Hypothesis : Mean of Upper Hemisphere <= Mean of Bottom Hemisphere")
p.zero <- pnorm(-m/s)
paste0("P value : ", p.zero)
means.age.groups <- data.frame(`Age Groups` = unique(data.suicides$age))
means <- numeric()
sds <- numeric()
len <- numeric()
counter <- 1
for(year in unique(data.suicides$age)){
dat <- data.suicides$suicides.100k.pop[data.suicides$age == year]
plot(density(dat), main = year, xlab = "Suicides per 100k people")
means[counter] <- mean(dat)
sds[counter] <- sd(dat)
len[counter] <- length(dat)
counter <- counter + 1
}
means.age.groups$`Mean Value` <- means
means.age.groups$`Standard Deviation` <- sds
means.age.groups$`S.D. of the Mean` <- sds/sqrt(len)
means.age.groups
generations <- data.frame(Generation = unique(data.suicides$generation))
means <- numeric()
sds <- numeric()
len <- numeric()
counter <- 1
for(gen in unique(data.suicides$generation)){
dat <- data.suicides$suicides.100k.pop[data.suicides$generation == gen]
means[counter] <- mean(dat)
sds[counter] <- sd(dat)
len[counter] <- length(dat)
counter <- counter + 1
}
generations$Mean <- means
generations$`Standard Deviation` <- sds
generations$`S.D. of the Mean` <- sds/sqrt(len)
generations
generations <- data.frame(Generation = unique(data.suicides$generation))
means <- numeric()
sds <- numeric()
len <- numeric()
counter <- 1
for(gen in unique(data.suicides$generation)){
dat <- data.suicides$suicides.100k.pop[data.suicides$generation == gen]
means[counter] <- mean(dat)
sds[counter] <- sd(dat)
len[counter] <- length(dat)
counter <- counter + 1
}
generations$Mean <- means
generations$`Standard Deviation` <- sds
generations$`S.D. of the Mean` <- sds/sqrt(len)
generations
generations <- data.frame(Generation = unique(data.suicides$generation))
means <- numeric()
sds <- numeric()
len <- numeric()
counter <- 1
coeff <- coefficients(lm(data.happiness$Happiness.Score~data.happiness$Economy..GDP.per.Capita.))
coeff <- as.numeric(coeff)
for(gen in unique(data.suicides$generation)){
dat <- data.suicides$gdp_per_capita[data.suicides$generation == gen]
dat <- dat / 1e4
dat <- coeff[1] + coeff[2]*dat
means[counter] <- mean(dat)
sds[counter] <- sd(dat)
len[counter] <- length(dat)
counter <- counter + 1
}
generations$`Mean ` <- means
generations$`Standard Deviation` <- sds
generations$`S.D. of the Mean` <- sds/sqrt(len)
generations
suicide <- read.csv("suicide_cleaned.csv")
library(dplyr)
suicide_new <- suicide
v <- NULL
for (i in 1:length(suicide$continent)) {
v[i] <- paste0(suicide$continent[i], ".", suicide$year[i])
}
suicide$continent.year <- v
# Plotting all the time series plots
suicide.2 <- suicide %>% group_by(continent.year) %>% summarise(suicide.tot.normal = (sum(suicides_no)/sum(population))*1e6 , year = year[1], continent = continent[1])
suicides <- split(suicide.2 , suicide.2$continent)
#time <- ts(data = suicides$Albania$suicide.tot.normal , start = min(suicides$Albania$year) , end = max(suicides$Albania$year))
time_series_plots <- c()
## all ts plots are stored by country name in time_series_plots object, save with write() if needed
for(i in unique(suicide$continent)){
data <- suicides[[i]]
time <- ts(data = data$suicide.tot.normal , start = min(data$year) , end = max(data$year))
plot.ts(time , xlab = "Year", ylab = "Suicide Rate Scaled" , main = i)
plt <- recordPlot()
time_series_plots[[i]] <- plt
}
#time_series_plots
suicide <- read.csv("suicide_cleaned.csv")
library(dplyr)
suicide_new <- suicide
v <- NULL
for (i in 1:length(suicide$continent)) {
v[i] <- paste0(suicide$continent[i], ".", suicide$year[i])
}
suicide$continent.year <- v
# Plotting all the time series plots
suicide.2 <- suicide %>% group_by(continent.year) %>% summarise(suicide.tot.normal = (sum(suicides_no)/sum(population))*1e6 , year = year[1], continent = continent[1])
suicides <- split(suicide.2 , suicide.2$continent)
#time <- ts(data = suicides$Albania$suicide.tot.normal , start = min(suicides$Albania$year) , end = max(suicides$Albania$year))
time_series_plots <- c()
## all ts plots are stored by country name in time_series_plots object, save with write() if needed
for(i in unique(suicide$continent)){
data <- suicides[[i]]
time <- ts(data = data$suicide.tot.normal , start = min(data$year) , end = max(data$year))
plot.ts(time , xlab = "Year", ylab = "Suicide Rate Scaled" , main = i)
plt <- recordPlot()
time_series_plots[[i]] <- plt
}
#time_series_plots
suicide <- read.csv("suicide_cleaned.csv")
library(dplyr)
suicide_new <- suicide
v <- NULL
for (i in 1:length(suicide$continent)) {
v[i] <- paste0(suicide$continent[i], ".", suicide$year[i])
}
suicide$continent.year <- v
# Plotting all the time series plots
suicide.2 <- suicide %>% group_by(continent.year) %>% summarise(suicide.tot.normal = (sum(suicides_no)/sum(population))*1e6 , year = year[1], continent = continent[1])
suicides <- split(suicide.2 , suicide.2$continent)
#time <- ts(data = suicides$Albania$suicide.tot.normal , start = min(suicides$Albania$year) , end = max(suicides$Albania$year))
time_series_plots <- c()
## all ts plots are stored by country name in time_series_plots object, save with write() if needed
for(i in unique(suicide$continent)){
data <- suicides[[i]]
time <- ts(data = data$suicide.tot.normal , start = min(data$year) , end = max(data$year))
plot.ts(time , xlab = "Year", ylab = "Suicide Rate Scaled" , main = i)
plt <- recordPlot()
time_series_plots[[i]] <- plt
}
#time_series_plots
data.final <- read.csv("../Happiness_Suicides.csv")
head(data.final)
library(rvest)
html <- read_html("https://www.myneta.info/andhrapradesh2019/index.php?action=summary&subAction=winner_serious_crime&sort=candidate#summary")
candidate_table <- html_nodes(html, ".w3-container .w3-table.w3-bordered")[[1]]
View(candidate_table)
xml_child(candidate_table, 7)
draws <- rbinom(10,1e3,.4)
plot(draws)
plot(density(draws))
draws <- rbinom(10,1e4,.4)
plot(density(draws))
set.seed(10)
draws <- rbinom(10,1e4,.4)
plot(density(draws))
hist(draws)
set.seed(10)
draws <- rbinom(1e4,10,.4)
hist(draws)
plot(density(draws))
hist(draws)
plot(density(draws))
hist(draws)
density(draws)
plot(density(draws))
hist(draws)
set.seed(10)
draws <- rbinom(1e4,10,.4)
hist(draws)
par(mfrow = c(2,1))
hist(draws)
par(mfrow = c(1,2))
hist(draws)
hist(proposals)
proposals <- rbinom(1e4,8,.6)
hist(proposals)
hist(draws)
proposals <- rbinom(1e4,8,.6)
hist(proposals)
hist(draws)
proposals <- rbinom(1e4,10,.6)
hist(proposals)
hist(draws)
proposals <- rbinom(1e4,8,.4)
hist(proposals)
hist(draws)
proposals <- rbinom(1e4,10,.5)
hist(proposals)
draws <- rnorm(1e4,10,.4) # bin(10,.4)
par(mfrow = c(1,2))
plot(density(draws))
proposals <- rnorm(1e4,8,.6)
plot(density(proposals))
plot(density(draws))
proposals <- rnorm(1e4,10,.6)
plot(density(proposals))
plot(density(draws))
proposals <- rnorm(1e4,8,.4)
plot(density(proposals))
plot(density(draws))
proposals <- rnorm(1e4,10,.5)
plot(density(proposals))
dat <- read_xlsx("Board_Data.clsx")
library(readxl)
dat <- read_xlsx("Board_Data.clsx")
setwd("~/IIM Internship/Board Data Analysis")
library(readxl)
dat <- read_xlsx("Board_Data.clsx")
dat.time <- read_xlsx("Time_query_data.xlsx")
dat <- read_xlsx("Board_Data.xlsx")
View(dat.time)
dat.time[-28]
dat.time <- dat.time[-28]
View(dat.time)
View(dat)
dat$`Total Compensation Paid to CEO 2023`[1]
as.numeric(dat$`Total Compensation Paid to CEO 2023`[1])
# Correcting for numerics
dat[2:27] <- as.numeric(dat[2:27])
dat[1]
dat[2:27]
# Correcting for numerics
dat[3:27] <- as.numeric(dat[3:27])
dat[3:27]
# Correcting for numerics
for(i in 3:27){
dat[i] <- as.numeric(dat[i])
}
dat[1]
dat[3]
as.numeric(dat[3])
library(dplyr)
# Correcting for numerics
for(i in 3:27){
dat[i] <- as.numeric(dat[i])
}
dat[[1]]
# Correcting for numerics
for(i in 3:27){
dat[i] <- as.numeric(dat[[i]])
}
for(i in 3:27){
dat.time[i] <- as.numeric(dat.time[[i]])
}
for(i in 33:52){
dat[i] <- as.numeric(dat[[i]])
}
save(dat, "Board_Data.Rdata")
save(dat, file = "Board_Data.Rdata")
save(dat.time, file = "Time_query_data.Rdata")
write_xlsx(dat, "Board_Data.xlsx")
write_xlsx(dat.time, "Time_query_data.xlsx")
# Storing the data
library(writexl)
write_xlsx(dat, "Board_Data.xlsx")
write_xlsx(dat.time, "Time_query_data.xlsx")
load("Board_Data.Rdata")
load("Time_query_data.Rdata")
load("Board_Data.Rdata")
load("Time_query_data.Rdata")
# Implementing a toy problem using Metropolois-Hastings Algorithm
set.seed(42)
##############################
# Problem : We want to run the MH algorithm to sample from a t dist.
N <- 1e4
k <- 73
iid.samples <- rt(n = N, df = k)
plot(density(iid.samples))
# Density function is dt
##############################
##############################
# Solution :
t_mh <- function(N = 1e3, k, h){
out.vect <- numeric(length = N)
acc.prob <- 0
out.vect[1] <- 30
for(t in 2:N){
prop.curr <- rnorm(1,out.vect[t-1],sqrt(h))
alpha <- dt(prop.curr, k)/dt(out.vect[t-1],k)
U.curr <- runif(1)
if(U.curr <= alpha){
out.vect[t] <- prop.curr
acc.prob <- acc.prob + 1
}
else{
out.vect[t] <- out.vect[t-1]
}
}
print(acc.prob/N)
return(out.vect)
}
chain <- t_mh(N,k,20)
plot(density(iid.samples))
lines(density(chain), col = "red")
plot.ts(iid.samples)
lines(1:N,chain,col = "red")
##############################
load("Board_Data.Rdata")
load("Board_Data.Rdata")
setwd("~/IIM Internship/IIMB_Internship")
load("Board_Data.Rdata")
load("Time_query_data.Rdata")
library(dplyr)
dat.time.2019 <- dat.time%>%
filter(!is.na(`Total Compensation Paid to CEO 2023`))
dat.time.2019$`Total Compensation Paid to CEO 2023` <- as.numeric(dat.time.2019$`Total Compensation Paid to CEO 2023`)
dat.time.2019 <- dat.time.2019%>%
filter(`Total Compensation Paid to CEO 2023` > 1e8)
dat.time.2019 <- dat.time.2019%>%
filter(`Total Compensation Paid to CEO 2023` < 1e10)
plot(density(dat.time.2019$`Total Compensation Paid to CEO 2023`/1e8))
lines(0:120, dnorm(0:120,20,5))
load("Board_Data.Rdata")
load("Time_query_data.Rdata")
library(dplyr)
dat.time.2019 <- dat.time%>%
filter(!is.na(`Total Compensation Paid to CEO 2023`))
View(dat.time.2019)
load("Board_Data.Rdata")
load("Time_query_data.Rdata")
library(dplyr)
# Loading the data that has no NA values for 2023 compensation
dat.time.2023 <- dat.time%>%
filter(!is.na(`Total Compensation Paid to CEO 2023`))
length(which(dat.time.2023$`Total Compensation Paid to CEO 2023` == dat.time.2023$`Total Compensation Paid to CEO 2022`))
common.dat <- dat.time.2023%>%
filter(`Total Compensation Paid to CEO 2023` == `Total Compensation Paid to CEO 2022`)
length(which(common.dat$`Total Compensation Paid to CEO 2022` == common.dat$`Total Compensation Paid to CEO 2021`))
length(which(common.dat$`Total Compensation Paid to CEO 2022` == common.dat$`Total Compensation Paid to CEO 2020`))
length(which(common.dat$`Total Compensation Paid to CEO 2022` == common.dat$`Total Compensation Paid to CEO 2019`))
common.dat <- common.dat%>%
filter(`Total Compensation Paid to CEO 2022` == `Total Compensation Paid to CEO 2021`)
common.dat <- common.dat%>%
filter(`Total Compensation Paid to CEO 2021` == `Total Compensation Paid to CEO 2020`)
common.dat <- common.dat%>%
filter(`Total Compensation Paid to CEO 2020` == `Total Compensation Paid to CEO 2019`)
View(common.dat)
common.dat$`Ticker ID`
common.dat[1]
length(unique(dat.time.2023$`Total Compensation Paid to CEO 2023`))
## Unique compensation values
length(unique(dat.time.2023$`Total Compensation Paid to CEO 2023`))
gc()
gc()
